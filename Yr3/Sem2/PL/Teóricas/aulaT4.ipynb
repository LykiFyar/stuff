{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula Teórica 4 (guião)\n",
    "### Semana de 13 a 17 de Março de 2023\n",
    "### José Carlos Ramalho\n",
    "### Sinopsis:\n",
    "\n",
    "* Analisadores Léxicos;\n",
    "* A ferramenta `ply`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisadores Léxicos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Símbolos terminais:\n",
    "1. Sinais: são constituídos por um caráter;\n",
    "2. Palavras reservadas: strings constantes;\n",
    "3. Terminais variáveis: identificadores, inteiros, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: a linguagem das listas\n",
    "\n",
    "Exemplos:\n",
    "\n",
    "```\n",
    "[]\n",
    "[2]\n",
    "[ 2, 4, 5]\n",
    "[ 2, 4, [ 5, 7, 9], 6]\n",
    "```\n",
    "\n",
    "Quais são os terminais:\n",
    "\n",
    "```\n",
    "T = {'[', ']', num}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação com o `re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "texto_input = \"\"\"\n",
    "[]\n",
    "[2]\n",
    "erro\n",
    "[ 2, 4, 5]\n",
    "???\n",
    "[ 2, 4, [ 5, 7, 9], 6]\n",
    "]23,-98[]\n",
    "\"\"\"\n",
    "\n",
    "for num,ap,fp,sep,skip,unk in re.findall(r'''\n",
    "         ([+-]?\\d+)             \n",
    "      |  (\\[)             \n",
    "      |  (\\])\n",
    "      |  (,)\n",
    "      |  (\\s+|\\t+) # skip \n",
    "      |  (.)       # situação de erro\n",
    "    ''', texto_input, re.I|re.X):\n",
    " \n",
    "    if   num      : print('NUM = ', num)\n",
    "    elif ap       : print('AP')\n",
    "    elif fp       : print('FP')\n",
    "    elif sep      : print('SEP')\n",
    "    elif skip     : pass\n",
    "    elif unk      : print('ERRO: ', unk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação com o `ply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PL2023: 14 de Março, jcr\n",
    "# ------------------------------------------------------------\n",
    "# listas.py\n",
    "#\n",
    "# tokenizer for a simple list language\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import ply.lex as lex\n",
    "\n",
    "# List of token names.   This is always required\n",
    "tokens = (\n",
    "   'NUM',\n",
    "   'AP',\n",
    "   'FP',\n",
    "   'SEP'\n",
    ")\n",
    "\n",
    "# Regular expression rules for simple tokens\n",
    "t_AP    = r'\\['\n",
    "t_FP   = r'\\]'\n",
    "t_SEP   = r','\n",
    "\n",
    "# A regular expression rule with some action code\n",
    "def t_NUM(t):\n",
    "    r'[+\\-]\\d+'\n",
    "    t.value = int(t.value)    \n",
    "    return t\n",
    "\n",
    "# Define a rule so we can track line numbers\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += len(t.value)\n",
    "\n",
    "# A string containing ignored characters (spaces and tabs)\n",
    "t_ignore  = ' \\t'\n",
    "\n",
    "# Error handling rule\n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "\n",
    "# Build the lexer\n",
    "lexer = lex.lex()\n",
    "\n",
    "# Test it out\n",
    "data = '''\n",
    "[]\n",
    "[2]\n",
    "erro\n",
    "[ 2, 4, 5]\n",
    "???\n",
    "[ 2, 4, [ 5, 7, 9], 6]\n",
    "]23,-98[]\n",
    "'''\n",
    "\n",
    "# Give the lexer some input\n",
    "lexer.input(data)\n",
    "\n",
    "for tok in lexer:\n",
    "    print(tok)\n",
    "    # print(tok.type, tok.value, tok.lineno, tok.lexpos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPC2: Somador on/off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PL2023: 14 de Março, jcr\n",
    "# ------------------------------------------------------------\n",
    "# somador_on_off.py\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import ply.lex as lex\n",
    "\n",
    "# List of token names.   This is always required\n",
    "tokens = (\n",
    "   'NUM',\n",
    "   'AP',\n",
    "   'FP',\n",
    "   'SEP'\n",
    ")\n",
    "\n",
    "# Regular expression rules for simple tokens\n",
    "t_AP    = r'\\['\n",
    "t_FP   = r'\\]'\n",
    "t_SEP   = r','\n",
    "\n",
    "# A regular expression rule with some action code\n",
    "def t_NUM(t):\n",
    "    r'[+\\-]\\d+'\n",
    "    t.value = int(t.value)    \n",
    "    return t\n",
    "\n",
    "# Define a rule so we can track line numbers\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += len(t.value)\n",
    "\n",
    "# A string containing ignored characters (spaces and tabs)\n",
    "t_ignore  = ' \\t'\n",
    "\n",
    "# Error handling rule\n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "\n",
    "# Build the lexer\n",
    "lexer = lex.lex()\n",
    "\n",
    "# Test it out\n",
    "data = '''\n",
    "[]\n",
    "[2]\n",
    "erro\n",
    "[ 2, 4, 5]\n",
    "???\n",
    "[ 2, 4, [ 5, 7, 9], 6]\n",
    "]23,-98[]\n",
    "'''\n",
    "\n",
    "# Give the lexer some input\n",
    "lexer.input(data)\n",
    "\n",
    "for tok in lexer:\n",
    "    print(tok)\n",
    "    print(tok.type, tok.value, tok.lineno, tok.lexpos)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
